{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim as s\n",
    "import torch.nn.functional as F\n",
    "import csv\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "import unicodedata\n",
    "import codecs\n",
    "import itertools\n",
    "import bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_filepath=os.path.join(\"cornell movie-dialogs corpus\",\"movie_lines.txt\")\n",
    "conv_filepath=os.path.join(\"cornell movie-dialogs corpus\",\"movie_conversations.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(lines_filepath,\"r\") as file:\n",
    "    lines=file.readlines()\n",
    "#for line in lines[:8]:\n",
    "    #print(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_fields=[\"lineID\",\"characterID\",\"movieID\",\"character\",\"text\"]\n",
    "lines={}\n",
    "with open(lines_filepath,\"r\",encoding=\"iso-8859-1\") as f:\n",
    "    for line in f:\n",
    "        values=line.split(\" +++$+++ \")\n",
    "        lineobj={}\n",
    "        for i,field in enumerate(line_fields):\n",
    "            lineobj[field]=values[i]\n",
    "        lines[lineobj[\"lineID\"]]=lineobj    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(conv_filepath,'r',encoding=\"iso-8859-1\") as f:\n",
    "    s_lines=f.readlines()\n",
    "#s_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_fields=[\"characterID\",\"character2ID\",\"movieID\",\"utteranceIDs\"]\n",
    "conversations=[]\n",
    "with open(conv_filepath,'r',encoding=\"iso-8859-1\") as f:\n",
    "    for line in f:\n",
    "        values=line.split(\" +++$+++ \")\n",
    "        convobj={}\n",
    "        for i,field in enumerate(conv_fields):\n",
    "            convobj[field]=values[i]\n",
    "        lineIds=eval(convobj[\"utteranceIDs\"])\n",
    "        convobj[\"lines\"]=[]\n",
    "        for lineId in lineIds:\n",
    "            convobj[\"lines\"].append(lines[lineId])\n",
    "        conversations.append(convobj)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_pairs=[]\n",
    "for conversation in conversations:\n",
    "    for i in range(len(conversation[\"lines\"])-1):\n",
    "        inputLine=conversation[\"lines\"][i][\"text\"].strip()\n",
    "        targetLine=conversation[\"lines\"][i+1][\"text\"].strip()\n",
    "        if inputLine and targetLine:\n",
    "            qa_pairs.append([inputLine,targetLine])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qa_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile=os.path.join(\"cornell movie-dialogs corpus\",\"fomatted_movie_lines.txt\")\n",
    "delimiter='\\t'\n",
    "delimiter=str(codecs.decode(delimiter,\"unicode_escape\"))\n",
    "#print(\"\\nwriting newly formatted file\")\n",
    "with open(datafile,'w',encoding=\"utf-8\") as outputfile:\n",
    "    writer=csv.writer(outputfile,delimiter=delimiter)\n",
    "    for pair in qa_pairs:\n",
    "        writer.writerow(pair)\n",
    "#print(\"done writing to file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile=os.path.join(\"cornell movie-dialogs corpus\",\"fomatted_movie_lines.txt\")\n",
    "with open(datafile,'rb') as file:\n",
    "    lines=file.readlines()\n",
    "#for line in lines[:8]:\n",
    "    #print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_token=0\n",
    "SOS_token=1\n",
    "EOS_token=2\n",
    "\n",
    "class vocabulary:\n",
    "    \n",
    "    def __init__(self,name):\n",
    "        self.name=name\n",
    "        self.word2index={}\n",
    "        self.word2count={}\n",
    "        self.index2word={PAD_token:\"PAD\",SOS_token:\"SOS\",EOS_token:\"EOS\"}\n",
    "        self.num_words=3\n",
    "    \n",
    "    def addsentence(self,sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addword(word)\n",
    "            \n",
    "    def addword(self,word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word]=self.num_words\n",
    "            self.word2count[word]=1\n",
    "            self.index2word[self.num_words]=word\n",
    "            self.num_words+=1\n",
    "        else:\n",
    "            self.word2count[word]+=1\n",
    "            \n",
    "    def trim(self,min_word):\n",
    "        keep_words=[]\n",
    "        for k,v in self.word2count.items():\n",
    "            if v>=min_word:\n",
    "                keep_words.append(k)\n",
    "        #print(\"keep_words {} / {}={:.4f}\".format((len(keep_words)),self.num_words,len(keep_words)/self.num_words))\n",
    "        self.word2index={}\n",
    "        self.word2count={}\n",
    "        self.index2word={PAD_token:\"PAD\",SOS_token:\"SOS\",EOS_token:\"EOS\"}\n",
    "        self.num_words=3\n",
    "        for word in keep_words:\n",
    "            self.addword(word)\n",
    "            \n",
    "    \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicodeToAscii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD',s) if unicodedata.category(c)!='Mn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unicodeToAscii(\"Maître Renard, par l’odeur alléché\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalisestring(s):\n",
    "    s=unicodeToAscii(s.lower().strip())\n",
    "    s=re.sub(r\"([.!?])\",r\" \\1\",s)\n",
    "    s=re.sub(r\"([^a-zA-Z.!?]+)\",r\" \",s)\n",
    "    s=re.sub(r\"\\s+\",r\" \",s).strip()\n",
    "    \n",
    "    return s\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile=os.path.join(\"cornell movie-dialogs corpus\",\"fomatted_movie_lines.txt\")\n",
    "delimiter='\\t'\n",
    "delimiter=str(codecs.decode(delimiter,\"unicode_escape\"))\n",
    "#print(\"\\nwriting newly formatted file\")\n",
    "with open(datafile,'w',encoding=\"utf-8\") as outputfile:\n",
    "    writer=csv.writer(outputfile,delimiter=delimiter)\n",
    "    for pair in qa_pairs:\n",
    "        pair[0]=normalisestring(pair[0])\n",
    "        pair[1]=normalisestring(pair[1])\n",
    "        writer.writerow(pair)\n",
    "#print(\"done writing to file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile=os.path.join(\"cornell movie-dialogs corpus\",\"fomatted_movie_lines.txt\")\n",
    "#print(\"Reading and processing file.....please wait\")\n",
    "lines=open(datafile,encoding=\"utf-8\").read().strip().split('\\n')\n",
    "pairs=[[normalisestring(s) for s in pair.split('\\t')] for pair in lines]\n",
    "#print(\"Done reading\")\n",
    "voc=vocabulary(\"cornell movie-dialogs corpus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH=10\n",
    "def filterpair(p):\n",
    "    return (len(p[0].split())<MAX_LENGTH and len(p[1].split())<MAX_LENGTH)\n",
    "def filterpairs(pairs):\n",
    "    return [pair for pair in pairs if filterpair(pair)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs=[pair for pair in pairs if len(pair)>1]\n",
    "#print(\"There are {} pairs/conversations in the dataset\".format(len(pairs)))\n",
    "pairs=filterpairs(pairs)\n",
    "#print(\"After filtering there are {} pairs/conversations in the dataset\".format(len(pairs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counted words: 17993\n"
     ]
    }
   ],
   "source": [
    "for pair in pairs:\n",
    "    voc.addsentence(pair[0])\n",
    "    voc.addsentence(pair[1])\n",
    "print(\"counted words:\",voc.num_words)\n",
    "#for pair in pairs[:10]:\n",
    "#   print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_COUNT=3\n",
    "\n",
    "def trimrarewords(voc,pairs,MIN_COUNT):\n",
    "    voc.trim(MIN_COUNT)\n",
    "    keep_pairs=[]\n",
    "    for pair in pairs:\n",
    "        input_sentence=pair[0]\n",
    "        output_sentence=pair[1]\n",
    "        keep_input=True\n",
    "        keep_output=True\n",
    "        for word in input_sentence.split(' '):\n",
    "            if word not in voc.word2index:\n",
    "                keep_input=False\n",
    "                break\n",
    "        for word in output_sentence.split(' '):\n",
    "            if word not in voc.word2index:\n",
    "                keep_output=False\n",
    "                break\n",
    "        if keep_input and keep_output:\n",
    "            keep_pairs.append(pair)\n",
    "    #print(\"Trimmed from {} pairs to {}, {:.4f} of total\".format(len(pairs),len(keep_pairs),len(keep_pairs)/len(pairs)))\n",
    "    return keep_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs=trimrarewords(voc,pairs,MIN_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pairs[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesfromsentence(voc,sentence):\n",
    "    return [voc.word2index[word] for word in sentence.split(' ')]+[EOS_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for pair in pairs:\n",
    "#pairs[0][0]\n",
    "#print(indexesfromsentence(voc,pairs[3][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pairs[4][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pairs[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[[1,2,3],[2,1]]\n",
    "a.append([1])\n",
    "#print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp=[]\n",
    "out=[]\n",
    "for pair in pairs[:10]:\n",
    "    inp.append(pair[0])\n",
    "    out.append(pair[1])\n",
    "#print(len(inp))\n",
    "indexes=[indexesfromsentence(voc,sentence) for sentence in inp]\n",
    "#indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[1,2,3,4,5]\n",
    "b=['a','s','d']\n",
    "#print(list(zip(a,b)))\n",
    "#list(itertools.zip_longest(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(itertools.zip_longest(*indexes,fillvalue=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeropadding(l,fillvalue=0):\n",
    "    return list(itertools.zip_longest(*l,fillvalue=fillvalue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "leng=[len(index) for index in indexes]\n",
    "#max(leng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result=zeropadding(indexes)\n",
    "#print(len(test_result))\n",
    "#test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binaryMatrix(l,value=0):\n",
    "    m=[]\n",
    "    for i,seq in enumerate(l):\n",
    "        m.append([])\n",
    "        for token in seq:\n",
    "            if token==PAD_token:\n",
    "                m[i].append(0)\n",
    "            else:\n",
    "                m[i].append(1)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[[1,2,3],[2,3]]\n",
    "a[1].append(2)\n",
    "#a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inputVar(l,voc):\n",
    "    indexes_batch=[indexesfromsentence(voc,sentence) for sentence in l]\n",
    "    lengths=[len(indexes) for indexes in indexes_batch]\n",
    "    padList=zeropadding(indexes_batch)\n",
    "    padVar=torch.LongTensor(padList)\n",
    "    \n",
    "    return padVar,lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outputVar(l,voc):\n",
    "    indexes_batch=[indexesfromsentence(voc,sentence) for sentence in l]\n",
    "    max_target_length=max([len(indexes) for indexes in indexes_batch])\n",
    "    padList=zeropadding(indexes_batch)\n",
    "    mask=binaryMatrix(padList)\n",
    "    mask=torch.ByteTensor(mask)\n",
    "    padVar=torch.LongTensor(padList)\n",
    "    \n",
    "    return padVar,mask,max_target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchTraindata(voc,pair_batch):\n",
    "    pair_batch.sort(key=lambda x:len(x[0].split(' ')),reverse=True)\n",
    "    input_batch,output_batch=[],[]\n",
    "    for pair in pair_batch:\n",
    "        input_batch.append(pair[0])\n",
    "        output_batch.append(pair[1])\n",
    "    inp,lengths=inputVar(input_batch,voc)\n",
    "    output,mask,max_target_length=outputVar(output_batch,voc)\n",
    "    \n",
    "    return inp,lengths,output,mask,max_target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_batch_size=5\n",
    "batches=batchTraindata(voc,[random.choice(pairs) for _ in range(small_batch_size)])\n",
    "input_variable,lengths,target_variable,mask,max_target_length=batches\n",
    "#print(\"input_variable:\")\n",
    "p=torch.nn.utils.rnn.pack_padded_sequence(input_variable,lengths)\n",
    "#print(p)\n",
    "#print(\"lengths:\")\n",
    "#print(lengths)\n",
    "#print(\"target_variable:\")\n",
    "#print(target_variable)\n",
    "#print(\"mask:\")\n",
    "#print(mask)\n",
    "#print(\"max_target_length:\")\n",
    "#print(max_target_length)\n",
    "#print(torch.nn.utils.rnn.pad_packed_sequence(p))\n",
    "#print(target_variable[max_target_length-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self,hidden_size,embedding,n_layers=1,dropout=0):\n",
    "        super(EncoderRNN,self).__init__()\n",
    "        self.n_layers=n_layers\n",
    "        self.hidden_size=hidden_size\n",
    "        self.embedding=embedding\n",
    "        self.gru=nn.GRU(hidden_size,hidden_size,n_layers,dropout=(0 if n_layers==1 else dropout),bidirectional=True)\n",
    "    def forward(self,input_seq,input_lengths,hidden=None):\n",
    "        embedded=self.embedding(input_seq)\n",
    "        packed=torch.nn.utils.rnn.pack_padded_sequence(embedded,input_lengths)\n",
    "        outputs,hidden=self.gru(packed,hidden)\n",
    "        outputs,_=torch.nn.utils.rnn.pad_packed_sequence(outputs)\n",
    "        outputs=outputs[:,:,:self.hidden_size]+outputs[:,:,self.hidden_size:]\n",
    "        \n",
    "        return outputs,hidden\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attn(torch.nn.Module):\n",
    "    def __init__(self,method,hidden_size):\n",
    "        super(Attn,self).__init__()\n",
    "        self.method=method\n",
    "        self.hidden_size=hidden_size\n",
    "    def dot_score(self,hidden,encoder_outputs):\n",
    "        return torch.sum(hidden*encoder_outputs,dim=2)\n",
    "    def forward(self,hidden,encoder_outputs):\n",
    "        attn_energies=self.dot_score(hidden,encoder_outputs)\n",
    "        attn_energies=attn_energies.t()\n",
    "        return F.softmax(attn_energies,dim=1).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LongAttnDecoderRNN(nn.Module):\n",
    "    def __init__(self,attn_model,embedding,hidden_size,output_size,n_layers=1,dropout=0.1):\n",
    "        super(LongAttnDecoderRNN,self).__init__()\n",
    "        self.attn_model=attn_model\n",
    "        self.hidden_size=hidden_size\n",
    "        self.output_size=output_size\n",
    "        self.n_layers=n_layers\n",
    "        self.dropout=dropout\n",
    "        \n",
    "        self.embedding=embedding\n",
    "        self.embedding_dropout=nn.Dropout(dropout)\n",
    "        self.gru=nn.GRU(hidden_size,hidden_size,n_layers,dropout=(0 if n_layers==1 else dropout))\n",
    "        self.concat=nn.Linear(2*hidden_size,hidden_size)\n",
    "        self.out=nn.Linear(hidden_size,output_size)\n",
    "        \n",
    "        self.attn=Attn(attn_model,hidden_size)\n",
    "    def forward(self,input_step,last_hidden,encoder_outputs):\n",
    "        embedded=self.embedding(input_step)\n",
    "        embedded=self.embedding_dropout(embedded)\n",
    "        rnn_output,hidden=self.gru(embedded,last_hidden)\n",
    "        attn_weights=self.attn(rnn_output,encoder_outputs)\n",
    "        context=attn_weights.bmm(encoder_outputs.transpose(0,1))\n",
    "        rnn_output=rnn_output.squeeze(0)\n",
    "        context=context.squeeze(1)\n",
    "        concat_input=torch.cat((rnn_output,context),1)\n",
    "        concat_output=torch.tanh(self.concat(concat_input))\n",
    "        output=self.out(concat_output)\n",
    "        output=F.softmax(output,dim=1)\n",
    "        return output,hidden\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maskNLLLoss(decoder_output,target,mask):\n",
    "    nTotal=mask.sum()\n",
    "    target=target.view(-1,1)\n",
    "   \n",
    "    gathered_tensor=torch.gather(decoder_output,1,target)\n",
    "    crossEntropy=-torch.log(gathered_tensor)\n",
    "    loss=crossEntropy.masked_select(mask)\n",
    "    loss=torch.mean(loss)\n",
    "    loss=loss.to(device)\n",
    "    return loss,nTotal.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_batch_size=5\n",
    "batches=batchTraindata(voc,[random.choice(pairs) for _ in range(small_batch_size)])\n",
    "input_variable,lengths,target_variable,mask,max_target_length=batches\n",
    "#print(\"input_variable shape:\")\n",
    "#print(input_variable.shape)\n",
    "lengths=torch.tensor(lengths)\n",
    "#print(\"lengths shape:\")\n",
    "#print(lengths.shape)\n",
    "#print(\"target_variable shape:\")\n",
    "#print(target_variable.shape)\n",
    "#print(\"mask shape:\")\n",
    "#print(mask.shape)\n",
    "#print(\"max_target_length:\")\n",
    "#print(max_target_length)\n",
    "hidden_size=500\n",
    "encoder_n_layers=2\n",
    "decoder_n_layers=2\n",
    "dropout=0.1\n",
    "attn_model='dot'\n",
    "embedding=nn.Embedding(voc.num_words,hidden_size)\n",
    "encoder=EncoderRNN(hidden_size,embedding,encoder_n_layers,dropout)\n",
    "decoder=LongAttnDecoderRNN(attn_model,embedding,hidden_size,voc.num_words,decoder_n_layers,dropout)\n",
    "encoder=encoder.to(device)\n",
    "decoder=decoder.to(device)\n",
    "encoder.train()\n",
    "decoder.train()\n",
    "encoder_optimizer=optim.Adam(encoder.parameters(),lr=0.0001)\n",
    "decoder_optimizer=optim.Adam(decoder.parameters(),lr=0.0001)\n",
    "input_variable=input_variable.to(device)\n",
    "lengths=lengths.to(device)\n",
    "target_variable=target_variable.to(device)\n",
    "mask=mask.to(device)\n",
    "loss=0\n",
    "print_losses=[]\n",
    "n_totals=0\n",
    "\n",
    "encoder_outputs,encoder_hidden=encoder(input_variable,lengths)\n",
    "#print(\"Encoder output's shape:\",encoder_outputs.shape)\n",
    "#print(\"Last encoder hidden shape:\",encoder_hidden.shape)\n",
    "decoder_input=torch.LongTensor([[SOS_token for _ in range(small_batch_size)]])\n",
    "decoder_input=decoder_input.to(device)\n",
    "#print(\"Initial decoder input shape\",decoder_input.shape)\n",
    "#print(decoder_input)\n",
    "decoder_hidden=encoder_hidden[:decoder.n_layers]\n",
    "#print(\"Initial decoder hidden state shape\",decoder_hidden.shape,\"\\n\")\n",
    "#print(\"----------------------------------------------------------------\")\n",
    "#print(\"Now let's look what's happening in every timestep of the GRU\")\n",
    "#print(\"----------------------------------------------------------------\")\n",
    "#print(\"\\n\")\n",
    "\n",
    "for t in range(max_target_length):\n",
    "    decoder_output,decoder_hidden=decoder(decoder_input,decoder_hidden,encoder_outputs)\n",
    "    #print(\"Decoder output shape:\",decoder_output.shape)\n",
    "    #print(\"Decoder hidden shape:\",decoder_hidden.shape)\n",
    "    \n",
    "    decoder_input=target_variable[t].view(1,-1)\n",
    "    #print(\"The target variable at the current timestep before reshaping\",target_variable[t])\n",
    "    #print(\"The target variable at the current timestep shape after reshaping\",target_variable[t].shape)\n",
    "    #print(\"The decoder input shape (reshape the target variable)\",decoder_input.shape)\n",
    "    \n",
    "    #print(\"The mask at the current timestep\",mask[t])\n",
    "    #print(\"The mask at the current timestep shape\",mask[t].shape)\n",
    "    mask_loss,nTotal=maskNLLLoss(decoder_output,target_variable[t],mask[t])\n",
    "    #print(\"Mask loss:\",mask_loss)\n",
    "    #print(\"Total:\",nTotal)\n",
    "    loss+=mask_loss\n",
    "    print_losses.append(mask_loss.item()*nTotal)\n",
    "    n_totals+=nTotal\n",
    "    #print(n_totals)\n",
    "    encoder_optimizer.step()\n",
    "    encoder_optimizer.step()\n",
    "    returned_loss=sum(print_losses)/n_totals\n",
    "    #print(\"Returned_loss:\",returned_loss)\n",
    "    #print(\"\\n\")\n",
    "    #print('-------------------------------DONE ONE TIMESTEP--------------------------------')\n",
    "    #print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_variable,lengths,target_variable,mask,max_target_len,encoder,decoder,embedding,encoder_optimizer,\n",
    "          decoder_optimizer,batch_size,clip,max_length=MAX_LENGTH):\n",
    "    \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    input_variable=input_variable.to(device)\n",
    "    lengths=torch.tensor(lengths).to(device)\n",
    "    target_variable=target_variable.to(device)\n",
    "    mask=mask.to(device)\n",
    "      \n",
    "    loss=0\n",
    "    print_losses=[]\n",
    "    n_totals=0\n",
    "    \n",
    "    encoder_outputs,encoder_hidden=encoder(input_variable,lengths)\n",
    "    \n",
    "    decoder_input=torch.tensor([[SOS_token for _ in range(batch_size)]])\n",
    "    decoder_input=decoder_input.to(device)\n",
    "    \n",
    "    decoder_hidden=encoder_hidden[:decoder.n_layers]\n",
    "    \n",
    "    use_teacher_forcing=True if random.random() > teacher_forcing_ratio else False\n",
    "    \n",
    "    if use_teacher_forcing:\n",
    "        for t in range(max_target_len):\n",
    "            decoder_output,decoder_hidden=decoder(decoder_input,decoder_hidden,encoder_outputs)\n",
    "            \n",
    "            decoder_input=target_variable[t].view(1,-1)\n",
    "            \n",
    "            mask_loss,nTotal=maskNLLLoss(decoder_output,target_variable[t],mask[t])\n",
    "            loss+=mask_loss\n",
    "            print_losses.append(mask_loss.item()*nTotal)\n",
    "            n_totals+=nTotal\n",
    "           \n",
    "            \n",
    "    else:\n",
    "        for t in range(max_target_len):\n",
    "            decoder_output,decoder_hidden=decoder(decoder_input,decoder_hidden,encoder_outputs)\n",
    "            _,topi=decoder_output.topk(1)\n",
    "            decoder_input=torch.LongTensor([[topi[i][0] for i in range(batch_size)]])\n",
    "            \n",
    "            mask_loss,nTotal=maskNLLLoss(decoder_output,target_variable[t],mask[t])\n",
    "            loss+=mask_loss\n",
    "            print_losses.append(mask_loss.item()*nTotal)\n",
    "            n_totals+=nTotal\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    torch.nn.utils.clip_grad_norm_(encoder.parameters(),clip)\n",
    "    torch.nn.utils.clip_grad_norm_(decoder.parameters(),clip)\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return sum(print_losses)/n_totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(model_name,voc,pairs,encoder,decoder,encoder_optimizer,decoder_optimizer,embedding,encoder_n_layers,\n",
    "               decoder_n_layers,save_dir,n_iteration,branch_size,print_every,save_every,clip,corpus_name,loadFilename):\n",
    "    training_batches=[batchTraindata(voc,[random.choice(pairs) for _ in range(batch_size)]) for _ in range(n_iteration)]\n",
    "    #print('Initialising.........')\n",
    "    start_iteration=1\n",
    "    print_loss=0\n",
    "    if loadFilename:\n",
    "        start_iteration=checkpoint['iteration']+1\n",
    "    #print('training....')\n",
    "    for iteration in range(start_iteration,n_iteration+1):\n",
    "        training_batch=training_batches[iteration-1]\n",
    "        input_variable,lengths,target_variable,mask,max_target_len=training_batch\n",
    "        \n",
    "        loss=train(input_variable,lengths,target_variable,mask,max_target_len,encoder,decoder,embedding,encoder_optimizer,decoder_optimizer,\n",
    "                  batch_size,clip)\n",
    "        print_loss+=loss\n",
    "        if iteration % print_every == 0:\n",
    "            print_avg_loss=print_loss/print_every\n",
    "            #print(\"Iteration:{},percent complete:{},Average loss:{}\".format(iteration,iteration*100/n_iteration,print_avg_loss))\n",
    "            print_loss=0\n",
    "        if iteration % save_every == 0:\n",
    "            directory=os.path.join(save_dir,model_name,corpus_name,'{}-{}_{}'.format(encoder_n_layers,decoder_n_layers,hidden_size))\n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory)\n",
    "            torch.save({'iteration':iteration,'en':encoder.state_dict(),'de':decoder.state_dict(),'en_opt':encoder_optimizer.state_dict(),\n",
    "                        'de_opt':decoder_optimizer.state_dict(),'loss':loss,'voc_dict':voc.__dict__,'embedding':embedding.state_dict()},\n",
    "                       os.path.join(directory,'{}_{}.tar'.format(iteration,'checkpoint')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GreedySearchDecoder(nn.Module):\n",
    "    def __init__(self,encoder,decoder):\n",
    "        super(GreedySearchDecoder,self).__init__()\n",
    "        self.encoder=encoder\n",
    "        self.decoder=decoder\n",
    "    def forward(self,input_seq,input_length,max_length):\n",
    "        encoder_outputs,encoder_hidden=self.encoder(input_seq,input_length)\n",
    "        decoder_hidden=encoder_hidden[:decoder.n_layers]\n",
    "        decoder_input=torch.ones(1,1,device=device,dtype=torch.long)*SOS_token\n",
    "        all_tokens=torch.zeros([0],device=device,dtype=torch.long)\n",
    "        all_scores=torch.zeros([0],device=device,dtype=torch.long)\n",
    "        for _ in range(max_length):\n",
    "            decoder_output,decoder_hidden=self.decoder(decoder_input,decoder_hidden,encoder_outputs)\n",
    "            decoder_score,decoder_input=torch.max(decoder_output,dim=1)\n",
    "            all_scores=torch.cat((all_scores,torch.LongTensor([decoder_score])),dim=0)\n",
    "            all_tokens=torch.cat((all_tokens,torch.LongTensor([decoder_input])),dim=0)\n",
    "            decoder_input=torch.unsqueeze(decoder_input,0)\n",
    "            \n",
    "        return all_tokens,all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder,decoder,searcher,voc,sentence,max_length=MAX_LENGTH):\n",
    "    indexes_batch=[indexesfromsentence(voc,sentence)]\n",
    "    lengths=torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "    input_batch=torch.LongTensor(indexes_batch).transpose(0,1)\n",
    "    input_batch=input_batch.to(device)\n",
    "    lengths=lengths.to(device)\n",
    "    tokens,scores=searcher(input_batch,lengths,max_length)\n",
    "    decoded_words=[voc.index2word[token.item()] for token in tokens]\n",
    "    return decoded_words\n",
    "\n",
    "def evaluateInput(encoder,decoder,searcher,voc):\n",
    "    input_sentence=''\n",
    "    p=[]\n",
    "    n_iteration=400\n",
    "    i=0\n",
    "    while(1):\n",
    "        try:\n",
    "            input_sentence=input('> ')\n",
    "            if (input_sentence=='q' or input_sentence=='quit'):\n",
    "                break\n",
    "            input_sentence=normalisestring(input_sentence)\n",
    "            output_words=evaluate(encoder,decoder,searcher,voc,input_sentence)\n",
    "            output_words[:]=[x for x in output_words if not(x=='EOS' or x=='PAD')]\n",
    "            print('BOT:',' '.join(output_words))\n",
    "            s=input('> ')\n",
    "            if s!='y' and s!='q':\n",
    "                p.append([])\n",
    "                s=normalisestring(s)\n",
    "                p[i].append(input_sentence)\n",
    "                p[i].append(s)\n",
    "                n_iteration+=1\n",
    "                i+=1\n",
    "        \n",
    "        except KeyError:\n",
    "            print(\"Error:Encountered unknown word.\")    \n",
    "    \n",
    "    if p!=[] and input_sentence=='q':\n",
    "        print_every=1\n",
    "        save_every=1\n",
    "                \n",
    "        datafile=os.path.join(\"cornell movie-dialogs corpus\",\"fomatted_movie_lines.txt\")\n",
    "        delimiter='\\t'\n",
    "        delimiter=str(codecs.decode(delimiter,\"unicode_escape\"))\n",
    "        print(\"\\nwriting newly formatted file\")\n",
    "        with open(datafile,'a',encoding=\"utf-8\") as outputfile:\n",
    "            writer=csv.writer(outputfile,delimiter=delimiter)        \n",
    "            for pair in p:\n",
    "                if pair not in pairs:\n",
    "                    print(1)\n",
    "                    writer.writerow(pair)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='cb_model'\n",
    "attn_model='dot'\n",
    "hidden_size=500\n",
    "encoder_n_layers=2\n",
    "decoder_n_layers=2\n",
    "dropout=0.2\n",
    "batch_size=100\n",
    "\n",
    "clip=50\n",
    "\n",
    "teacher_forcing_ratio=1.0\n",
    "learning_rate=0.00005\n",
    "decoder_learning_ratio=5.0\n",
    "\n",
    "#loadFilename=os.path.join(\"cornell movie-dialogs corpus\",\"cb_model\",\"trained_data\",\"2-2_500\",\"70000_checkpoint.tar\")\n",
    "checkpoint_iter=4000\n",
    "loadFilename=None\n",
    "if loadFilename:\n",
    "    checkpoint=torch.load(loadFilename)\n",
    "    encoder_sd=checkpoint['en']\n",
    "    decoder_sd=checkpoint['de']\n",
    "    encoder_optimizer_sd=checkpoint['en_opt']\n",
    "    decoder_optimizer_sd=checkpoint['de_opt']\n",
    "    embedding_sd=checkpoint['embedding']\n",
    "    voc.__dicy__=checkpoint['voc_dict']\n",
    "#print(\"building and encoder.....\")\n",
    "embedding=nn.Embedding(voc.num_words,hidden_size)\n",
    "if loadFilename:\n",
    "    embedding.load_state_dict(embedding_sd)\n",
    "    encoder=EncoderRNN(hidden_size,embedding,encoder_n_layers,dropout)\n",
    "    decoder=LongAttnDecoderRNN(attn_model,embedding,hidden_size,voc.num_words,decoder_n_layers,dropout)\n",
    "if loadFilename:\n",
    "    encoder.load_state_dict(encoder_sd)\n",
    "    decoder.load_state_dict(decoder_sd)\n",
    "encoder=encoder.to(device)\n",
    "decoder=decoder.to(device)\n",
    "#print('models built and ready to go')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip=50\n",
    "teacher_forcing_ratio=1.0\n",
    "learning_rate=0.000001\n",
    "decoder_learning_ratio=5.0\n",
    "n_iteration=70500\n",
    "print_every=1\n",
    "save_every=500\n",
    "\n",
    "encoder.train()\n",
    "decoder.train()\n",
    "\n",
    "#print(\"building optimizers\")\n",
    "encoder_optimizer=optim.Adam(encoder.parameters(),lr=learning_rate)\n",
    "decoder_optimizer=optim.Adam(decoder.parameters(),lr=learning_rate*decoder_learning_ratio)\n",
    "if loadFilename:\n",
    "    encoder_optimizer.load_state_dict(encoder_optimizer_sd)\n",
    "    decoder_optimizer.load_state_dict(decoder_optimizer_sd)\n",
    "#print(\"start training!\")\n",
    "trainIters(model_name,voc,pairs,encoder,decoder,encoder_optimizer,decoder_optimizer,embedding,encoder_n_layers,decoder_n_layers,\n",
    "           \"cornell movie-dialogs corpus\",n_iteration,batch_size,print_every,save_every,clip,\"trained_data\",loadFilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.eval()\n",
    "\n",
    "decoder.eval()\n",
    "searcher=GreedySearchDecoder(encoder,decoder)\n",
    "evaluateInput(encoder,decoder,searcher,voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair=[\"hey\",normalisestring(\"hey,how are you?\")]\n",
    "c=1 if pair in pairs else 0\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=os.path.join(\"ubuntu_dialogs.tgz\")\n",
    "with open(d,\"r\",encoding=\"iso-8859-1\") as f:\n",
    "    lines=f.readlines()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=[['aadfd'],['adadg']]\n",
    "p[0].append('fa')\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=[]\n",
    "#p.append(['gda'])\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=1 if \"word\" in voc.index2word.values() else 0\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc.word2index['bot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc.num_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "e=encoder.embedding\n",
    "e(torch.tensor([7826]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(29500,68000,500):\n",
    "    filename=str(i)+(\"_checkpoint.tar\")\n",
    "    loadFilename=os.path.join(\"cornell movie-dialogs corpus\",\"cb_model\",\"trained_data\",\"2-2_500\",filename)\n",
    "\n",
    "    if loadFilename:\n",
    "        checkpoint=torch.load(loadFilename)\n",
    "        loss=checkpoint['loss']\n",
    "        print(i,\":\",loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,10,2):\n",
    "    print(str(i)+('weeee'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
